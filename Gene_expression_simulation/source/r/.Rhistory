toc()
tic()
output<-FReMA(ped,
num.resamples=20,
family="binomial",
penalty = "randomized"
model = "additive",
resample = "subsampling") #runs FreMA on the example data
toc()
tic()
output<-FReMA(ped,
num.resamples=20,
family="binomial",
penalty = "randomized",
model = "additive",
resample = "subsampling") #runs FreMA on the example data
toc()
tic()
output<-FReMA(ped,
num.resamples=20,
family="binomial",
penalty = "randomized",
model = "additive",
) #runs FreMA on the example data
toc()
tic()
output<-FReMA(ped,
num.resamples=20,
family="binomial",
#penalty = "randomized",
model = "additive",
) #runs FreMA on the example data
toc()
install.packages("C:/Users/zayed/Downloads/llarrma_1.01.tar_.gz", repos = NULL)
install.packages("C:/Users/zayed/Downloads/llarrma_1.01.tar_.gz", repos = NULL,type = "winbinary")
library(llarrma)
?`llarrma-package`
?llarrma
data("llarrma")  #contains a ped object named "ped"
output<-llarrma(ped, num.subsamples=20, penalty="lasso", method.lambda="perm", family="binomial")
output
summary(output)
output_incmat <- output$inc.mat
dim(output_incmat)
summary(output_incmat)
library(llarrma)
library(FReMA)
library(tidyverse)
library(BGData)
library(tictoc)
# Restrict number of cores to 1 on Windows
if (.Platform$OS.type == "windows") {
options(mc.cores = 1)
}
load.BGData("ProjData/BGData_new2.RData")
#make objects needed for constructing PEDfile
subjectID <- seq(1,3100,by=1)
markerID <- DATA@map$snp
geno <- DATA@geno
fatherID <- rep(0,times=3100)
motherID <- rep(0,times=3100)
familyID <- seq(1,3100,by=1)
sexID <- rep(0,3100)
pheno <- DATA@pheno$height.cm
library(tidyverse)
library(BGData)
library(tictoc)
library(readxl)
library(LDheatmap)
library(snpStats)
library(reshape2)
# Restrict number of cores to 1 on Windows
if (.Platform$OS.type == "windows") {
options(mc.cores = 1)
}
load.BGData("ProjData/BGData_new2.RData")
gwasdata <- read_excel("ProjData/new.gwasdata2.xlsx")
theme_Publication <- function(base_size=14, base_family="helvetica") {
library(grid)
library(ggthemes)
(theme_foundation(base_size=base_size, base_family=base_family)
+ theme(plot.title = element_text(face = "bold",
size = rel(1.2), hjust = 0.5),
text = element_text(),
panel.background = element_rect(colour = NA),
plot.background = element_rect(colour = NA),
panel.border = element_rect(colour = NA),
axis.title = element_text(face = "bold",size = rel(1)),
axis.title.y = element_text(angle=90,vjust =2),
axis.title.x = element_text(vjust = -0.2),
axis.text = element_text(),
axis.line = element_line(colour="black"),
axis.ticks = element_line(),
panel.grid.major = element_line(colour="#f0f0f0"),
panel.grid.minor = element_blank(),
legend.key = element_rect(colour = NA),
legend.position = "bottom",
legend.direction = "horizontal",
legend.key.size= unit(0.2, "cm"),
legend.margin = unit(0, "cm"),
legend.title = element_text(face="italic"),
plot.margin=unit(c(10,5,5,5),"mm"),
strip.background=element_rect(colour="#f0f0f0",fill="#f0f0f0"),
strip.text = element_text(face="bold")
))
}
llarma.mod  <- readRDS(file = "LLARMA_mod.RDS")
llarma.mod2 <- readRDS(file = "LLARMA_mod2.RDS")
#Extract inclusion matrix
inclusion_matrix <- as.data.frame(llarma.mod$inc.mat)
inclusion_matrix2 <- as.data.frame(llarma.mod2$inc.mat)
#compute RMIP and store as dataframe
RMIP.df <- as.data.frame(rowSums(inclusion_matrix)/1000)
RMIP.df2 <- as.data.frame(rowSums(inclusion_matrix2)/2000)
SNPs <- llarma.mod$predictors
SNPs2 <- llarma.mod2$predictors
#lambda.vals <- llarma.mod$lambdas
colnames(RMIP.df)[1] <- "RMIP"
colnames(RMIP.df2)[1] <- "RMIP_2"
#rownames(RMIP.df) <- SNPs
RMIP.df <- cbind(SNPs,RMIP.df)
RMIP.df2 <- cbind(SNPs2,RMIP.df2)
colnames(RMIP.df)[1] <- "snp"
colnames(RMIP.df2)[1] <- "snp"
#Extract non-zero RMIPs
llarma.sparse <- RMIP.df %>% filter(RMIP > 0)
llarma.sparse2 <- RMIP.df2 %>% filter(RMIP_2 > 0)
#Therefore we have reduced the number of predictors from 62534 to 164
#However, there are still only 22 causal SNPs We need to check whether or not
#LLARMA correctly identified the 22 causals or at least the top 3 causals
#merge LLARMA RMIPS to original GWAS data
gwasdata <- merge(gwasdata,RMIP.df,by="snp")
library(tidyverse)
library(data.table)
library(BGData)
#setwd("C:/Users/zayed/Desktop/Coursework/Research/data")
# Restrict number of cores to 1 on Windows
if (.Platform$OS.type == "windows") {
options(mc.cores = 1)
}
gene.matrix <- as.data.frame(fread("geno.txt"))
gene_support <- read.delim("gene_support.txt")
snv_support <- read.delim("snv_support.txt")
phenotypes <- read.delim("pheno.txt")
View(gene_support)
View(gene.matrix)
View(phenotypes)
View(phenotypes)
View(gene_support)
View(snv_support)
hist(snv_support)
hist(snv_support$DAF)
View(snv_support)
library(tidyverse)
library(readr)
library(writexl)
library(readxl)
library(reshape2)
library(randomForest)
library(tictoc)
library(caret)
library(tidyverse)
library(readr)
library(readxl)
library(writexl)
`%notin%` <- Negate(`%in%`)
teiq_final <- read_csv("teiq_dat_final (1).csv")
mfs_final <- read_csv("mfs_dat_final (1).csv")
Cnst <- read_excel("Cnst.xlsx")
Anonimizer_func2 <- function(x){
a <- strsplit(x,split=" ")[[1]][1]
b <- strsplit(x,split=" ")[[1]][2]
y <- paste(substr(tolower(a),1,3),substr(tolower(b),1,3),sep="_")
return(y)
}
table(mfs_final$Group)
?predict
library(tidyverse)
library(susieR)
library(BGData)
library(readxl)
library(tictoc)
library(LDheatmap)
library(snpStats)
if (.Platform$OS.type == "windows") {
options(mc.cores = 1)
}
load.BGData("BGData_new2.RData")
gwasdata <- read_excel("new.gwasdata2.xlsx")
DATA@geno[6,6]
DATA@geno[1:6,1:6]
library(ape)
library(adegenet)
dna <- fasta2DNAbin(file="http://adegenet.r-forge.r-project.org/files/usflu.fasta")
annot <- read.csv("http://adegenet.r-forge.r-project.org/files/usflu.annot.csv",
header=TRUE,
row.names=1)
annot
D <- dist.dna(dna,
model = "TN93")
temp <- as.data.frame(as.matrix(D))
heatmap(as.matrix(temp),
Rowv = NULL,
Colv = NULL) #Set Rowv and Colv to NULL and this will stop clustering
tre <- nj(D)
class(tre)
tre <- ladderize(tre)
plot(tre)
dnds(dna)
tre <- ladderize(tre)
plot(tre)
data("woodmouse")
res <- dnds(woodmouse)
?dnds
res <- dnds(woodmouse,code = 1)
res <- dnds(woodmouse,
code = 1,
return.categories = TRUE)
res <- dnds(woodmouse,
code = 1,
details = TRUE)
data("woodmouse")
res <- dnds(woodmouse,
code = 1,
details = TRUE)
library(ape)
library(adegenet)
data("woodmouse")
res <- dnds(woodmouse,
code = 1,
details = TRUE)
data("woodmouse")
res <- dnds(woodmouse,
code = 1)
res
x <- rnorm(n=100,
mean=0,
sd=1)
x <- rnorm(n=100,
mean=0,
sd=1)
y <- data.frame(value=x,
id=1:length(x))
View(y)
yrank <- data.frame(value=unique(y$value),
rank=rank(unique(y$value)))
View(yrank)
?rank
?%%
%%
library(glmnet)
?cv.glmnet
install.packages("phyclust")
library(phyclust)
?paml.baseml
?paml.baseml.control
?phyclust
types <- list(c())
View(types)
View(types)
types[[1]] <-0
View(types)
types[[2]] <-2
?unique
geno[geno[,i] != '',i]
?paste0
sample(c("Head","Tail"),size=1)
plot(1:100,(1:200)^2)
# Install and load required packages
install.packages("glmnet")
library(glmnet)
# Example data (replace this with your actual dataset)
set.seed(123)
n <- 100
p <- 10
strat <- rep(1:5, each = n/5)
x <- matrix(rnorm(n * p), ncol = p)
y <- rnorm(n)
# Combine data into a data frame
data <- data.frame(strat, x, y)
# Function to fit elastic net model with k-fold cross-validation
fit_enet_cv <- function(data, indices, k = 5) {
# Subset data based on bootstrap indices
boot_data <- data[indices, ]
# Extract predictors and response
x_boot <- boot_data[, -1]  # Assuming the first column is the stratifying variable
y_boot <- boot_data[, 1]   # Assuming the first column is the response variable
# Check if the response variable has variability
if (length(unique(y_boot)) <= 1) {
# If y is constant, return NA or an appropriate placeholder
return(rep(NA, length(y_boot)))
}
# Create a fold index vector for cross-validation
fold_indices <- sample(1:k, length(y_boot), replace = TRUE)
# Initialize an empty vector to store the cross-validated predictions
cv_preds <- numeric(length = length(y_boot))
# Perform k-fold cross-validation
for (fold in 1:k) {
# Split data into training and validation sets
x_train <- x_boot[fold_indices != fold, ]
y_train <- y_boot[fold_indices != fold]
x_valid <- x_boot[fold_indices == fold, ]
# Fit elastic net model on training data
enet_model <- cv.glmnet(x_train, y_train, alpha = 0.5)
# Make predictions on the validation set
cv_preds[fold_indices == fold] <- predict(enet_model, newx = x_valid, s = "lambda.min")
}
# Return cross-validated predictions
return(cv_preds)
}
# Set up bootstrap
n_bootstrap <- 1000  # Number of bootstrap samples
bootstrap_indices <- unlist(lapply(1:n_bootstrap,
function(i) sample(1:n, replace = TRUE)))
# Perform bootstrap and fit elastic net models with k-fold CV
boot_results <- lapply(bootstrap_indices, fit_enet_cv, data = data)
# Display results (for example, predictions for the first observation in each bootstrap sample)
head(sapply(boot_results, function(cv_preds) cv_preds[1]))
#retrieve the first element of the simulated gene expression dataset
gnex.dir = file.path(anaDir,"01")
#############################################################################################################
#
# This is a main init script for an RNA-seq simulation project;
#
# Program:  init-SeqNet-sim-main.r
# Version:
# Author:   zshahjahan
# Purpose:  Initializes important global variables. This includes knitR setup.
# Input:
# Output:  	N/A
#############################################################################################################
##
##The raw data was downloaded from this link: https://www.kaggle.com/datasets/lachmann12/human-liver-rnaseq-gene-expression-903-samples/data
##Manually decompressed and stored in the dtaDir location
## reset variables
rm(list=ls(all=TRUE))
#Directories section
projDir = file.path("C:/Users/zayed/OneDrive/Desktop/Research_v2.0/SeqNet_playthru")
srcDir  = file.path(projDir,"source")
workDir = file.path(srcDir,"r")
funDir  = file.path(workDir,"functions")
dtaDir  = file.path(projDir,"data")
## NOTE: subdirectories under the analysis directory should correspond to the
## modules from which the objects, tables or models are being created from
## however, the exception to this should be any reference genome, transcriptome
## or database that has been downloaded and processed and may be used by multiple
## programs
anaDir  = file.path(projDir,"analysis")
resDir  = file.path(projDir,"report")
tblDir  = file.path(resDir,"tab")
pltDir  = file.path(resDir,"fig")
#Working directory should be the r folder under source dir
setwd(workDir)
#Source functions from script containing functions in the function directory
source(file.path(funDir,"init-functions.r"))
#My system using MRAN instead of CRAN, this is causing dependency issues
#trying this code will apparently help. UPDATE: and it does :)
# local({r = getOption("repos")
# r["CRAN"] = "http://cran.r-project.org"
# options(repos=r)})
options(repos = c(CRAN = "https://cloud.r-project.org"))
#Vector of software packages required for this project; modify this whenever
#a new package is to be used.
#NOTE: tidyverse is a real pain to work with, just load dplyr instead and work
#with that
libs = c("dplyr",
"SeqNet",
"data.table",
"edgeR",
"GenomicFeatures",
"rtracklayer",
"stringr",
"gridExtra",
"cowplot",
"lme4",
"MASS",
"rmutil",
"glmnet",
"ggplot2",
"Cairo")
## load libraries using the shared R library
# Use sapply to check and install packages
#sapply(libs, check_and_install)
## load libraries using the shared R library
lapply(libs, require, character.only=T)
#Set a random seed
set.seed(80085)
#subset about 1000 random rows (genes) and 500 columns (samples)
#Earlier I arbitrarily chose the numbers below, but I am going pick the sample
#size and gene size numbers to reflect the sample and gene numbers from the
#paper by Goll et al. 2018
## Initialize analysis objects
#new idea, use common processes of the liver and group these together and simulated
#co-expression
#TG always
liverPtwVect=c("bile",
"bilirubin",
"Cytochrome",
"conjugation")
#Specify study population covariate groups using the following analysis variables
covariateObjList = list(treatSite = c("Site A","Site B","Site C","Site D"),
treatType = c("TRT","PLAC"),
sexVar    = c("M","F"),
tranplType = c("HEST","SOTL"),
ethnVar    = c("ethn_1","ethn_2","ethn_3","ethn_4"))
#Construct analysis-by objects. These are the conditions used
#Flag to perform TMM-normalization
tmmFlag = c("no-TMM"=0,"TMM"=1)
#Flag to analyze reference gene expression or simulated gene expression
#Names of vectors correspond to the naming convention from SeqNet::gen_rnaseq()
refSim = c("reference"=0,"x"=1)
#Usually the metadata should be loaded when the main init script is called
#but this script is an exception
#Set up hyperparameters related to tuning the linear model to be used
alphaVals = seq(0,1,0.01)
nBoot=500
nFold=15
percBoot=0.25 #percentage of
#Obtain standardization flags for the gene expression data
stdFlags = c('org','std');
stdLabls = c('Original Variables','Standardized Variables');
suppressMessages(source(file.path("C:/Users/zayed/OneDrive/Desktop/Research_v2.0/SeqNet_playthru",
"source","r","init-SeqNet-sim-main.r")))
#retrieve the first element of the simulated gene expression dataset
gnex.dir = file.path(anaDir,"01")
gnex.df.list = readRDS(file.path(gnex.dir,"bile_sim_gnexp.RDS"))
sim.gene.exp = gnex.df.list[["x"]]
#retrieve the metadata
mta.df = read.csv(file.path(anaDir,"project_metadata.csv"))
#retrieve the immunology dataset
imm.df = read.csv(file.path(anaDir,"immunology_outcome.csv"))
enet.mod = cv.glmnet(x=sim.gene.exp,y=imm.df[,"immune_response"])
enet.mod = glmnet(x=sim.gene.exp,y=imm.df[,"immune_response"])
plot(enet.mod)
print(enet.mod)
coef.set=coef(enet.mod,s=0.1)
cv.enet.mod = cv.glmnet(x=sim.gene.exp,y=imm.df[,"immune_response"],nfolds = 25)
plot(cv.enet.mod)
nBoot=500
#Create a subdirectory under analysis and module-03 and store the bootstrapped
#results
boot.results.dir = file.path(anaDir,"03","bootstrapped_results")
if(!dir.exists(boot.results.dir)){
dir.create(boot.results.dir)
}
#From the original dataset, resample a certain number of points
#Resample 25% of the original dataset
bootstrapped.samid = sample(imm.df$SAMID,replace=T)
y.boot = imm.df %>% filter(SAMID %in% bootstrapped.samid)
#Keep only the immunogenictiy variable
y.boot = data.frame(lg10_immune=log10(y.boot[,"immune_response"]),
SAMID = y.boot$SAMID)
#Do the same thing for the metadata and the design matrix
x.boot = sim.gene.exp[rownames(sim.gene.exp) %in% bootstrapped.samid,]
x.small = as.data.frame(x.boot[,c(3:9)])
x.small$SAMID= rownames(x.small)
mydat = merge(y.boot,x.small,by="SAMID")
mydat.mta = merge(mydat,mta.df,by="SAMID",all.x=T)
p=ggplot(mydat.mta,
aes(x=ACOT8,y=lg10_immune))+
geom_point(aes(shape=tranplType),#Shape aesthetics for points go here
stat="identity",size=4,alpha=0.5) #No statistical transformations
p+facet_grid(cols=vars(sexVar))+theme_bw()
base.plot=ggplot(mydat.mta,aes(x=-log2(AKR1C3),y=lg10_immune))
View(mydat.mta)
connected_scatter=base.plot+geom_line()+geom_point()
connected_scatter
hist_immu = ggplot(mydat.mta, aes(x=lg10_immune))+
geom_histogram()+labs("Immunogenicity Assay")+theme(text = element_text(family="berling"))
#geom_line or geom_path for maps, geom_polygon for frequency polygons
mydat.mta = mydat.mta %>% mutate(Day=gsub("T","",tmpt))
#Take the log2 of the read counts before passing to the cv.glmnet function
x.boot = log10((x.boot+0.05))
cv.boot = cv.glmnet(data.frame(x.boot),y.boot$lg10_immune,nfolds = nFold)
colnames(mydat.mta)
ggplot(mydat.mta,aes(x=Day,y=lg10_immune,group=tranplType))+geom_line()
table(mydat.mta$treatSite)
mydat.mta.site = mydat.mta %>% filter(treatSite=="Site A")
ggplot(mydat.mta.site,aes(x=Day,y=lg10_immune,group=tranplType))+geom_line()
View(mydat.mta.site)
ggplot(mydat.mta.site,aes(x=Day,y=lg10_immune,group=PATID))+geom_line()
ggplot(mydat.mta.site,aes(x=Day,y=lg10_immune,group=PATID))+geom_line()+scale_color_viridis_b()
ggplot(mydat.mta.site,aes(x=Day,y=lg10_immune,group=PATID,color=treatType))+geom_line()+scale_color_viridis_b()
ggplot(mydat.mta.site,aes(x=Day,y=lg10_immune,group=PATID,color=treatType))+geom_line()+scale_color_viridis_b(discrete=T)
?scale_color_viridis_b
ggplot(mydat.mta.site,aes(x=Day,y=lg10_immune,group=PATID,color=treatType))+geom_line()+scale_color_viridis(discrete=T)
install.packages("viridis")
library(viridis)
ggplot(mydat.mta.site,aes(x=Day,y=lg10_immune,group=PATID,color=treatType))+
geom_line()+
scale_color_viridis(discrete=T)
ggplot(mydat.mta.site,aes(x=Day,y=lg10_immune,group=PATID,color=treatType))+
geom_pcp()+
scale_color_viridis(discrete=T)
ggplot(mydat.mta.site,aes(x=Day,y=lg10_immune,group=PATID,color=treatType))+
geom_path()+
scale_color_viridis(discrete=T)
ggplot(mydat.mta.site,aes(x=Day,y=lg10_immune,group=PATID,color=treatType))+
geom_point()+
geom_path()+
scale_color_viridis(discrete=T)
mydat.mta.site %>% group_by(PATID) %>% summarise(Avg_lg10 = mean(lg10_immune))
%>%
mydat.mta.site = mydat.mta %>% filter(treatSite=="Site A")
mydat.mta.site %>% group_by(PATID) %>%
summarise(Avg_lg10 = mean(lg10_immune))%>%
ggplot(aes(x=Day,y=Avg_lg10,group=PATID,color=treatType))+
geom_point()+
geom_path()+
scale_color_viridis(discrete=T)
mydat.mta.site %>% group_by(PATID) %>%
summarise(Avg_lg10 = mean(lg10_immune))
